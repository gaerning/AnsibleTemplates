---

- hosts: all
#  vars:
    # Obviously change this if you are not in this Rackspace datacenter (or at Rackspace at all)
#    - toplevel_timeservers: ['time.ord1.rackspace.com', 'time.ord2.rackspace.com']
    
    # TIMELORD IS THE KEEPER OF ALL OF THE TIME
    # This variable currently assumes that each server can be referenced by its own group. If this is 
    # not the case, edit ntp.conf to instead look for a defined inventory_hostname if you would rather reference it that way.
    # You can easily find where this is used in ntp.conf by searching for 'timelord' or 'groups[timelord][0]'
    # This is also used a bit later on in the handlers for this playbook
    - timelord: '192.168.33.132'
    
    # The ethernet device that the servers will communicate over. If applicable, change this to the one connected to your VPN
#    - ntp_netdevice: 'eth0'
    
  tasks:
    - name: Install NTP
      apt: package=ntp,ntpdate state=present update_cache=yes
      tags: ntp
  
    - name: Copy over the NTP configuration
      template: src=ntp.conf dest=/etc/ntp.conf
      notify:
        - restart ntp
        - force ntp update
      tags: ntp
    
    - name: Make sure NTP is started up
      service: name=ntp state=started enabled=yes
      tags: ntp

#    - name: Open inbound NTP connections for the timelord, time giver to all
#      shell: ufw allow from {{ hostvars[inventory_hostname]['ansible_' ~ ntp_netdevice]['ipv4']['network'] }}/{{ hostvars[inventory_hostname]['ansible_' ~ ntp_netdevice]['ipv4']['netmask'] }} to any port 123
#      when: timelord is defined and ansible_hostname == timelord
#      tags: ntp
      
  handlers:
    - name: restart ntp
      service: name=ntp state=restarted
  
    - name: force ntp update
      shell: "service ntp stop && ntpdate -s 192.168.33.132 && service ntp start"
#      when: ansible_hostname != timelord
